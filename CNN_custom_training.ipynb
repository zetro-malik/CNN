{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "################# Parameters #####################\n",
    "\n",
    "# folder with all the class folders\n",
    "path = \"D:\\Machine Learning Projects\\CNN notebooks\\myData\"\n",
    "# file with all names of classes\n",
    "labelFile = 'D:\\Machine Learning Projects\\CNN notebooks\\labels.csv'\n",
    "batch_size_val = 8  # how many to process together\n",
    "steps_per_epoch_val = 2000\n",
    "epochs_val = 20\n",
    "imageDimesions = (256, 256, 3)\n",
    "testRatio = 0.2    # if 1000 images split will 200 for testing\n",
    "validationRatio = 0.2  # if 1000 images 20% of remaining 800 will be 160 for validation\n",
    "###################################################\n",
    "\n",
    "\n",
    "# Importing of the Images\n",
    "count = 0\n",
    "images = []\n",
    "classNo = []\n",
    "myList = os.listdir(path)\n",
    "print(\"Total Classes Detected:\", len(myList))\n",
    "noOfClasses = len(myList)\n",
    "print(\"Importing Classes.....\")\n",
    "for x in range(0, len(myList)):\n",
    "    myPicList = os.listdir(path+\"/\"+str(count))\n",
    "    for y in myPicList:\n",
    "        curImg = cv2.imread(path+\"/\"+str(count)+\"/\"+y)\n",
    "        curImg = cv2.resize(curImg, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "        images.append(curImg)\n",
    "        classNo.append(count)\n",
    "    print(count, end=\" \")\n",
    "    count += 1\n",
    "print(\" \")\n",
    "images = np.array(images)\n",
    "classNo = np.array(classNo)\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    images, classNo, test_size=testRatio)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "    X_train, y_train, test_size=validationRatio)\n",
    "\n",
    "# X_train = ARRAY OF IMAGES TO TRAIN\n",
    "# y_train = CORRESPONDING CLASS ID\n",
    "\n",
    "# TO CHECK IF NUMBER OF IMAGES MATCHES TO NUMBER OF LABELS FOR EACH DATA SET\n",
    "print(\"Data Shapes\")\n",
    "print(\"Train\", end=\"\")\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(\"Validation\", end=\"\")\n",
    "print(X_validation.shape, y_validation.shape)\n",
    "print(\"Test\", end=\"\")\n",
    "print(X_test.shape, y_test.shape)\n",
    "assert (X_train.shape[0] == y_train.shape[0]\n",
    "        ), \"The number of images in not equal to the number of lables in training set\"\n",
    "assert (X_validation.shape[0] == y_validation.shape[0]\n",
    "        ), \"The number of images in not equal to the number of lables in validation set\"\n",
    "assert (X_test.shape[0] == y_test.shape[0]\n",
    "        ), \"The number of images in not equal to the number of lables in test set\"\n",
    "assert (X_train.shape[1:] == (imageDimesions)\n",
    "        ), \" The dimesions of the Training images are wrong \"\n",
    "assert (X_validation.shape[1:] == (imageDimesions)\n",
    "        ), \" The dimesionas of the Validation images are wrong \"\n",
    "assert (X_test.shape[1:] == (imageDimesions)\n",
    "        ), \" The dimesionas of the Test images are wrong\"\n",
    "\n",
    "\n",
    "# READ CSV FILE\n",
    "data = pd.read_csv(labelFile)\n",
    "print(\"data shape \", data.shape, type(data))\n",
    "\n",
    "\n",
    "# PREPROCESSING THE IMAGES\n",
    "\n",
    "\n",
    "def grayscale(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img\n",
    "\n",
    "\n",
    "def equalize(img):\n",
    "    img = cv2.equalizeHist(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def preprocessing(img):\n",
    "    img = grayscale(img)     # CONVERT TO GRAYSCALE\n",
    "    img = equalize(img)      # STANDARDIZE THE LIGHTING IN AN IMAGE\n",
    "    img = img/255            # TO NORMALIZE VALUES BETWEEN 0 AND 1 INSTEAD OF 0 TO 255\n",
    "    return img\n",
    "\n",
    "\n",
    "# TO IRETATE AND PREPROCESS ALL IMAGES\n",
    "X_train = np.array(list(map(preprocessing, X_train)))\n",
    "X_validation = np.array(list(map(preprocessing, X_validation)))\n",
    "X_test = np.array(list(map(preprocessing, X_test)))\n",
    "# TO CHECK IF THE TRAINING IS DONE PROPERLY\n",
    "\n",
    "# ADD A DEPTH OF 1\n",
    "X_train = X_train.reshape(\n",
    "    X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_validation = X_validation.reshape(\n",
    "    X_validation.shape[0], X_validation.shape[1], X_validation.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "\n",
    "\n",
    "# AUGMENTATAION OF IMAGES: TO MAKEIT MORE GENERIC\n",
    "dataGen = ImageDataGenerator(width_shift_range=0.1,   # 0.1 = 10%     IF MORE THAN 1 E.G 10 THEN IT REFFERS TO NO. OF  PIXELS EG 10 PIXELS\n",
    "                             height_shift_range=0.1,\n",
    "                             zoom_range=0.2,  # 0.2 MEANS CAN GO FROM 0.8 TO 1.2\n",
    "                             shear_range=0.1,  # MAGNITUDE OF SHEAR ANGLE\n",
    "                             rotation_range=10,\n",
    "                             )  # DEGREES\n",
    "dataGen.fit(X_train)\n",
    "# REQUESTING DATA GENRATOR TO GENERATE IMAGES  BATCH SIZE = NO. OF IMAGES CREAED EACH TIME ITS CALLED\n",
    "batches = dataGen.flow(X_train, y_train, batch_size=20)\n",
    "X_batch, y_batch = next(batches)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['oaifa','khubaib','zeeshan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "cnn = models.Sequential([\n",
    "        #cnn\n",
    "        layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=(256,256,1)),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu'),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        \n",
    "\n",
    "        #dense\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')    \n",
    "    ])\n",
    "\n",
    "cnn.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "cnn.fit(X_batch, y_batch, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.evaluate(X_test,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import numpy as np\n",
    "def grayscale(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img\n",
    "\n",
    "\n",
    "def equalize(img):\n",
    "    img = cv2.equalizeHist(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def preprocessing(img):\n",
    "    img = grayscale(img)\n",
    "    img = equalize(img)\n",
    "    img = img/255\n",
    "    return img\n",
    "\n",
    "\n",
    "def getCalssName(classNo):\n",
    "    if classNo == 0:\n",
    "        return 'ozaifa'\n",
    "    elif classNo == 1:\n",
    "        return 'Khubaib'\n",
    "    elif classNo == 2:\n",
    "        return 'zeeshan'\n",
    "\n",
    "\n",
    "imgOrignal = cv2.imread(\n",
    "    r\"myData\\1\\WhatsApp Image 2023-03-29 at 4.58.12 PM.jpeg\")\n",
    "\n",
    "# PROCESS IMAGE\n",
    "img = np.asarray(imgOrignal)\n",
    "img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "img = preprocessing(img)\n",
    "cv2.imshow(\"Processed Image\", img)\n",
    "img = img.reshape(1, 256, 256, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cnn.predict(img)\n",
    "print(classes[np.argmax(y_pred)],np.amax(y_pred))\n",
    "plt.imshow(cv2.imread(r\"myData\\1\\WhatsApp Image 2023-03-29 at 4.58.12 PM.jpeg\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnn.save(\"Face_recognition.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using .h5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"Face_recognition.h5\")\n",
    "y_pred=model.predict(img)\n",
    "print(classes[np.argmax(y_pred)],np.amax(y_pred))\n",
    "plt.imshow(cv2.imread(r\"myData\\1\\WhatsApp Image 2023-03-29 at 4.58.12 PM.jpeg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
